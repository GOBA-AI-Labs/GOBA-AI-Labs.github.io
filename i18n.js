(function () {
  const KEY = 'goba-lang';

  const translations = {
    en: {
      'nav.models': 'Models',
      'nav.technology': 'Technology',
      'nav.huggingface': 'HuggingFace',
      'nav.support': 'Support Us',
      'hero.title': 'Half the experts.<br>Full quality.',
      'hero.subtitle': 'We remove up to 50% of MoE experts while preserving benchmark scores. Proven on models up to 80B \u2014 our goal is 400B+ on consumer hardware.',
      'hero.browse': 'Browse Models',
      'hero.huggingface': 'HuggingFace',
      'hero.stat': 'Qwen3.5-35B-A3B \u2014 20% expert pruning, MMLU 80%, fits 24GB Mac GPU',
      'nav.tools': 'Tools',
      'nav.paper': 'Paper',
      'models.title': 'PrunedHub Models',
      'models.desc': '8 pruned MoE models ready to run. All compatible with llama.cpp. Qwen3/3.5 also work with moe-stream.',
      'model.new': 'NEW',
      'model.mxmoe': 'MxMoE',
      'model.qwen35.desc': 'DeltaNet hybrid, 256 experts. Pruned within 24h of release. Full GPU-resident on 24GB Mac. MMLU -1pp.',
      'model.enmxmoe.desc': 'EN-optimized pruning + mixed quantization (Q5K/Q4K/Q3K). 22% smaller, GSM8K 94%.',
      'model.jpmxmoe.desc': 'JP language-aware pruning + MxMoE. GSM8K 96%, Japanese quality preserved.',
      'tools.title': 'Inference Tools',
      'tools.desc': 'Run pruned MoE models on consumer hardware.',
      'tools.moestream.tagline': 'SSD-streaming MoE inference engine for Apple Silicon & Linux',
      'tools.moestream.ssd': '80B models with 4GB RAM via NVMe SSD streaming',
      'tools.moestream.adaptive': 'Layer-adaptive pruning support (experts_per_layer)',
      'tools.moestream.speed': 'Q4 quantized matmul \u2014 +79% speedup',
      'tools.moestream.metal': 'Metal GPU + CUDA + CPU hybrid inference',
      'tools.moestream.cicd': 'CI/CD with pre-built binaries for macOS & Linux',
      'tools.moestream.python': 'Python bindings (PyO3)',
      'tools.moestream.github': 'View on GitHub',
      'model.lossless': 'Lossless',
      'model.50pruned': '50% Pruned',
      'model.japanese': 'Japanese',
      'model.experimental': 'Experimental',
      'model.gptoss28.desc': 'Zero quality loss across all benchmarks. MMLU 78%, HumanEval 78%, GSM8K 92%. Fits 16GB RAM.',
      'model.qwen80b.desc': '80B model compressed to 24GB. MMLU 72%. At 44% pruning (27.7 GB): LCB Easy 83%, HumanEval 72%.',
      'model.jp30b.desc': 'Language-aware pruning preserves Japanese quality. Thinking-ON: MMLU 79%, JA 90%.',
      'model.zerobias.desc': 'Router optimization recovers quality at the pruning cliff. -1pp with 15.6% fewer experts.',
      'tech.title': 'How It Works',
      'tech.desc': 'Expert pruning, not aggressive quantization.',
      'tech.calibration': 'Calibration-Based Scoring',
      'tech.calibration.desc': 'Expert importance measured through actual inference on diverse workloads. Significantly more accurate than static weight analysis.',
      'tech.adaptive': 'Layer-Adaptive Allocation',
      'tech.adaptive.desc': 'Each layer retains a dynamically determined number of experts. Some layers are more sensitive to pruning \u2014 adaptive allocation preserves quality where it matters.',
      'tech.language': 'Language-Aware Optimization',
      'tech.language.desc': 'Automatic detection and protection of language-specialized experts. Japanese, Chinese, and other language capabilities preserved during compression.',
      'tech.zerobias': 'Zerobias Router Optimization',
      'tech.zerobias.desc': 'Post-pruning router bias correction extends the lossless compression frontier. Zero cost, no retraining required.',
      'comp.title': 'Expert Pruning vs Quantization',
      'comp.pruning': 'Expert Pruning',
      'comp.quantization': 'Q2 Quantization',
      'comp.approach': 'Approach',
      'comp.pruning.approach': 'Remove redundant experts entirely',
      'comp.quant.approach': 'Reduce precision of all weights',
      'comp.quality': 'Quality impact',
      'comp.pruning.quality': 'Targeted, minimal',
      'comp.quant.quality': 'Uniform degradation',
      'comp.24gb': '~24 GB model quality',
      'comp.pruning.24gb': 'MMLU 72%',
      'comp.quant.24gb': 'MMLU ~55\u201360%',
      'comp.precision': 'Remaining precision',
      'comp.pruning.precision': 'Full Q4 precision',
      'comp.quant.precision': '2-bit precision',
      'vision.title': 'Where This Is Going',
      'vision.desc': 'Expert pruning is just the beginning. Here\'s what becomes possible.',
      'vision.hardware': 'Consumer Hardware',
      'vision.hardware.desc': 'Frontier-class MoE models on a laptop with 24GB RAM \u2014 no $10K+ server GPU required. Democratizing access to the most capable AI.',
      'vision.energy': 'Lower Energy Cost',
      'vision.energy.desc': 'Fewer experts means fewer FLOPs per token. Data centers could serve the same quality at half the compute \u2014 significant power savings at scale.',
      'vision.rl': 'Post-Pruning RL',
      'vision.rl.desc': 'Pruned models create headroom for targeted reinforcement learning. Same size, potentially better performance \u2014 quality amplification, not just preservation.',
      'vision.edge': 'Edge Deployment',
      'vision.edge.desc': 'MoE models become viable for on-device inference. Private, fast, and offline \u2014 bringing expert-level AI to phones and embedded systems.',
      'models.goba.title': 'GOBA Models',
      'models.goba.desc': 'Domain-tuned models using our Expert-as-Adapter technique. Pruned expert slots repurposed for specialization.',
      'model.experttuned': 'Expert Tuned',
      'model.olmoe.domains': 'Domains',
      'model.olmoe.desc': '3 domain-tuned variants via Expert-as-Adapter. JA +4.5pp JMMLU, Code +10pp HumanEval+, Finance +16pp fraud detection.',
      'models.research.title': 'Research Highlights',
      'models.research.80b': '80B Code Generation Finding',
      'models.research.80b.desc': '50% expert pruning preserves MMLU 76% but destroys code generation (HumanEval 0%). Code generation uses 84% of experts \u2014 a distributed capability that resists pruning.',
      'models.research.qwen35': 'Qwen3.5-35B-A3B: Day-1 Pruning',
      'models.research.qwen35.desc': 'Pruned within 24 hours of release. 5 methods compared on 256-expert DeltaNet hybrid. Weight-based pruning wins: MMLU 80% (-1pp), LiveCodeBench Easy 83.1% (142 problems). Published on HuggingFace.',
      'tech.adapter': 'Expert-as-Adapter',
      'tech.adapter.desc': 'Pruned expert slots become domain adapters. A LoRA alternative using the MoE architecture itself \u2014 no external modules, native router integration.',
      'cta.title': 'Built on a MacBook. Funded by You.',
      'cta.detail': 'This entire research \u2014 29+ phases, 6 model families, 8 published models, 100+ experiments \u2014 was conducted on a single MacBook Pro (M4 Pro, 24GB RAM, 512GB SSD). No data center. No corporate funding.',
      'cta.funding': 'Your support directly funds GPU access to test on larger models, cloud compute for comprehensive benchmarking, and time to continue open-source research.',
      'cta.button': 'Support on Ko-fi',
      'footer.name': 'GOBA-AI-Labs',
    },
    ja: {
      'nav.models': '\u30E2\u30C7\u30EB',
      'nav.technology': '\u6280\u8853',
      'nav.huggingface': 'HuggingFace',
      'nav.support': '\u652F\u63F4\u3059\u308B',
      'hero.title': 'Expert\u534A\u5206\u3002<br>\u54C1\u8CEA\u305D\u306E\u307E\u307E\u3002',
      'hero.subtitle': 'MoE\u30E2\u30C7\u30EB\u306Eexpert\u3092\u6700\u592750%\u524A\u9664\u3057\u3001\u30D9\u30F3\u30C1\u30DE\u30FC\u30AF\u30B9\u30B3\u30A2\u3092\u7DAD\u6301\u300280B\u30E2\u30C7\u30EB\u3067\u5B9F\u8A3C\u6E08\u307F \u2014 \u76EE\u6A19\u306F400B+\u3092\u30B3\u30F3\u30B7\u30E5\u30FC\u30DE\u30FC\u30CF\u30FC\u30C9\u30A6\u30A7\u30A2\u3067\u3002',
      'hero.browse': '\u30E2\u30C7\u30EB\u4E00\u89A7',
      'hero.huggingface': 'HuggingFace',
      'hero.stat': 'Qwen3.5-35B-A3B \u2014 20% expert pruning, MMLU 80%, fits 24GB Mac GPU',
      'nav.tools': '\u30C4\u30FC\u30EB',
      'nav.paper': '\u8AD6\u6587',
      'models.title': 'PrunedHub \u30E2\u30C7\u30EB',
      'models.desc': '8\u3064\u306Epruned MoE\u30E2\u30C7\u30EB\u3002\u5168\u3066llama.cpp\u5BFE\u5FDC\u3002Qwen3/3.5\u306Fmoe-stream\u3067\u3082\u5B9F\u884C\u53EF\u80FD\u3002',
      'model.new': 'NEW',
      'model.mxmoe': 'MxMoE',
      'model.qwen35.desc': 'DeltaNet\u30CF\u30A4\u30D6\u30EA\u30C3\u30C9\u3001256 experts\u3002\u30EA\u30EA\u30FC\u30B9\u304B\u308924\u6642\u9593\u4EE5\u5185\u306Bpruning\u300224GB Mac\u3067\u5168GPU\u5E38\u99D0\u3002MMLU -1pp\u3002',
      'model.enmxmoe.desc': 'EN\u6700\u9069\u5316pruning + \u6DF7\u5408\u91CF\u5B50\u5316 (Q5K/Q4K/Q3K)\u3002-22%\u30B5\u30A4\u30BA\u3001GSM8K 94%\u3002',
      'model.jpmxmoe.desc': 'JA\u8A00\u8A9E\u5BFE\u5FDCpruning + MxMoE\u3002GSM8K 96%\u3001\u65E5\u672C\u8A9E\u54C1\u8CEA\u7DAD\u6301\u3002',
      'tools.title': '\u63A8\u8AD6\u30C4\u30FC\u30EB',
      'tools.desc': '\u30B3\u30F3\u30B7\u30E5\u30FC\u30DE\u30FC\u30CF\u30FC\u30C9\u30A6\u30A7\u30A2\u3067pruned MoE\u30E2\u30C7\u30EB\u3092\u5B9F\u884C\u3002',
      'tools.moestream.tagline': 'Apple Silicon\u30FBCUDA\u30FBLinux\u5411\u3051SSD\u30B9\u30C8\u30EA\u30FC\u30DF\u30F3\u30B0MoE\u63A8\u8AD6\u30A8\u30F3\u30B8\u30F3',
      'tools.moestream.ssd': '80B\u30E2\u30C7\u30EB\u30924GB RAM\u3067\u5B9F\u884C\uFF08NVMe SSD\u30B9\u30C8\u30EA\u30FC\u30DF\u30F3\u30B0\uFF09',
      'tools.moestream.adaptive': '\u30EC\u30A4\u30E4\u30FC\u9069\u5FDC\u578Bpruning\u5BFE\u5FDC\uFF08experts_per_layer\uFF09',
      'tools.moestream.speed': 'Q4\u91CF\u5B50\u5316matmul \u2014 +79%\u9AD8\u901F\u5316',
      'tools.moestream.metal': 'Metal GPU + CUDA + CPU\u30CF\u30A4\u30D6\u30EA\u30C3\u30C9\u63A8\u8AD6',
      'tools.moestream.cicd': 'CI/CD\u3068macOS\u30FBLinux\u5411\u3051\u30D3\u30EB\u30C9\u6E08\u307F\u30D0\u30A4\u30CA\u30EA',
      'tools.moestream.python': 'Python\u30D0\u30A4\u30F3\u30C7\u30A3\u30F3\u30B0 (PyO3)',
      'tools.moestream.github': 'GitHub\u3067\u898B\u308B',
      'model.lossless': '\u30ED\u30B9\u30EC\u30B9',
      'model.50pruned': '50% \u524A\u6E1B',
      'model.japanese': '\u65E5\u672C\u8A9E\u5BFE\u5FDC',
      'model.experimental': '\u5B9F\u9A13\u7684',
      'model.gptoss28.desc': '全ベンチマークで品質劣化ゼロ。MMLU 78%、HumanEval 78%、GSM8K 92%。16GB RAMに収まる。',
      'model.qwen80b.desc': '80Bモデルを24GBに圧縮。MMLU 72%。44% pruning (27.7 GB)時: LCB Easy 83%、HumanEval 72%。',
      'model.jp30b.desc': '\u8A00\u8A9E\u5BFE\u5FDC\u30D7\u30EB\u30FC\u30CB\u30F3\u30B0\u3067\u65E5\u672C\u8A9E\u54C1\u8CEA\u3092\u7DAD\u6301\u3002Thinking-ON: MMLU 79%, JA 90%\u3002',
      'model.zerobias.desc': '\u30EB\u30FC\u30BF\u30FC\u6700\u9069\u5316\u3067pruning cliff\u306E\u54C1\u8CEA\u3092\u56DE\u5FA9\u3002expert 15.6%\u524A\u6E1B\u3067-1pp\u3002',
      'tech.title': '\u6280\u8853\u306E\u4ED5\u7D44\u307F',
      'tech.desc': '\u904E\u5EA6\u306A\u91CF\u5B50\u5316\u3067\u306F\u306A\u304F\u3001expert\u30D7\u30EB\u30FC\u30CB\u30F3\u30B0\u3002',
      'tech.calibration': '\u30AD\u30E3\u30EA\u30D6\u30EC\u30FC\u30B7\u30E7\u30F3\u30D9\u30FC\u30B9\u30B9\u30B3\u30A2\u30EA\u30F3\u30B0',
      'tech.calibration.desc': '\u591A\u69D8\u306A\u30EF\u30FC\u30AF\u30ED\u30FC\u30C9\u3067\u306E\u5B9F\u969B\u306E\u63A8\u8AD6\u3092\u901A\u3058\u3066expert\u306E\u91CD\u8981\u5EA6\u3092\u6E2C\u5B9A\u3002\u9759\u7684\u91CD\u307F\u5206\u6790\u3088\u308A\u5927\u5E45\u306B\u9AD8\u7CBE\u5EA6\u3002',
      'tech.adaptive': '\u30EC\u30A4\u30E4\u30FC\u9069\u5FDC\u578B\u5272\u5F53',
      'tech.adaptive.desc': '\u5404\u30EC\u30A4\u30E4\u30FC\u304C\u52D5\u7684\u306B\u6C7A\u5B9A\u3055\u308C\u305F\u6570\u306Eexpert\u3092\u4FDD\u6301\u3002\u30D7\u30EB\u30FC\u30CB\u30F3\u30B0\u306B\u654F\u611F\u306A\u30EC\u30A4\u30E4\u30FC\u306E\u54C1\u8CEA\u3092\u512A\u5148\u7684\u306B\u4FDD\u5168\u3002',
      'tech.language': '\u8A00\u8A9E\u5BFE\u5FDC\u6700\u9069\u5316',
      'tech.language.desc': '\u8A00\u8A9E\u7279\u5316expert\u306E\u81EA\u52D5\u691C\u51FA\u3068\u4FDD\u8B77\u3002\u65E5\u672C\u8A9E\u30FB\u4E2D\u56FD\u8A9E\u7B49\u306E\u8A00\u8A9E\u80FD\u529B\u3092\u5727\u7E2E\u6642\u306B\u7DAD\u6301\u3002',
      'tech.zerobias': 'Zerobias\u30EB\u30FC\u30BF\u30FC\u6700\u9069\u5316',
      'tech.zerobias.desc': '\u30D7\u30EB\u30FC\u30CB\u30F3\u30B0\u5F8C\u306E\u30EB\u30FC\u30BF\u30FCbias\u88DC\u6B63\u3067\u30ED\u30B9\u30EC\u30B9\u5727\u7E2E\u306E\u9650\u754C\u3092\u62E1\u5F35\u3002\u30B3\u30B9\u30C8\u30BC\u30ED\u3001\u518D\u8A13\u7DF4\u4E0D\u8981\u3002',
      'comp.title': 'Expert\u30D7\u30EB\u30FC\u30CB\u30F3\u30B0 vs \u91CF\u5B50\u5316',
      'comp.pruning': 'Expert\u30D7\u30EB\u30FC\u30CB\u30F3\u30B0',
      'comp.quantization': 'Q2\u91CF\u5B50\u5316',
      'comp.approach': '\u30A2\u30D7\u30ED\u30FC\u30C1',
      'comp.pruning.approach': '\u5197\u9577\u306Aexpert\u3092\u5B8C\u5168\u306B\u524A\u9664',
      'comp.quant.approach': '\u5168\u91CD\u307F\u306E\u7CBE\u5EA6\u3092\u524A\u6E1B',
      'comp.quality': '\u54C1\u8CEA\u3078\u306E\u5F71\u97FF',
      'comp.pruning.quality': '\u7684\u3092\u7D5E\u3063\u305F\u6700\u5C0F\u9650\u306E\u5F71\u97FF',
      'comp.quant.quality': '\u4E00\u69D8\u306A\u54C1\u8CEA\u52A3\u5316',
      'comp.24gb': '~24 GB\u30E2\u30C7\u30EB\u54C1\u8CEA',
      'comp.pruning.24gb': 'MMLU 72%',
      'comp.quant.24gb': 'MMLU ~55\uFF5E60%',
      'comp.precision': '\u6B8B\u5B58\u7CBE\u5EA6',
      'comp.pruning.precision': 'Q4\u30D5\u30EB\u7CBE\u5EA6',
      'comp.quant.precision': '2\u30D3\u30C3\u30C8\u7CBE\u5EA6',
      'vision.title': 'この先にあるもの',
      'vision.desc': 'Expert pruningは始まりに過ぎません。ここから何が可能になるか。',
      'vision.hardware': 'コンシューマーハードウェア',
      'vision.hardware.desc': 'フロンティアクラスのMoEモデルを24GB RAMのノートPCで \u2014 10万円超のサーバーGPU不要。最高性能AIへのアクセスを民主化。',
      'vision.energy': '低消費電力',
      'vision.energy.desc': 'expertが減ればトークンあたりのFLOPsも減少。データセンターは同等品質を半分の計算量で提供可能 \u2014 大規模な省電力を実現。',
      'vision.rl': 'プルーニング後の強化学習',
      'vision.rl.desc': 'プルーニング済みモデルは強化学習の余地を生む。同サイズでより高い性能 \u2014 品質の保持だけでなく増幅の可能性。',
      'vision.edge': 'エッジデプロイメント',
      'vision.edge.desc': 'MoEモデルがオンデバイス推論で実用可能に。プライベート、高速、オフライン \u2014 expertレベルのAIをスマートフォンや組込みシステムへ。',
      'models.goba.title': 'GOBA \u30E2\u30C7\u30EB',
      'models.goba.desc': 'Expert-as-Adapter\u6280\u8853\u306B\u3088\u308B\u30C9\u30E1\u30A4\u30F3\u7279\u5316\u30E2\u30C7\u30EB\u3002pruning\u3067\u7A7A\u3044\u305Fexpert\u30B9\u30ED\u30C3\u30C8\u3092\u5C02\u9580\u5316\u306B\u518D\u5229\u7528\u3002',
      'model.experttuned': 'Expert\u30C1\u30E5\u30FC\u30CB\u30F3\u30B0',
      'model.olmoe.domains': '\u30C9\u30E1\u30A4\u30F3',
      'model.olmoe.desc': 'Expert-as-Adapter\u306B\u3088\u308B3\u30C9\u30E1\u30A4\u30F3\u7279\u5316\u30D0\u30EA\u30A2\u30F3\u30C8\u3002JA +4.5pp JMMLU\u3001Code +10pp HumanEval+\u3001Finance +16pp\u4E0D\u6B63\u691C\u77E5\u3002',
      'models.research.title': '\u7814\u7A76\u30CF\u30A4\u30E9\u30A4\u30C8',
      'models.research.80b': '80B\u30B3\u30FC\u30C9\u751F\u6210\u306E\u77E5\u898B',
      'models.research.80b.desc': '50% expert pruning\u3067MMLU 76%\u3092\u7DAD\u6301\u3059\u308B\u304C\u3001\u30B3\u30FC\u30C9\u751F\u6210\u306F\u5D29\u58CA\uFF08HumanEval 0%\uFF09\u3002\u30B3\u30FC\u30C9\u751F\u6210\u306Fexpert\u306E84%\u3092\u4F7F\u7528 \u2014 pruning\u306B\u8010\u6027\u306E\u306A\u3044\u5206\u6563\u7684\u80FD\u529B\u3002',
      'models.research.qwen35': 'Qwen3.5-35B-A3B: Day-1 Pruning',
      'models.research.qwen35.desc': '\u30EA\u30EA\u30FC\u30B9\u304B\u308924\u6642\u9593\u4EE5\u5185\u306Bpruning\u5B8C\u4E86\u3002256 expert DeltaNet\u30CF\u30A4\u30D6\u30EA\u30C3\u30C9\u30675\u624B\u6CD5\u3092\u6BD4\u8F03\u3002Weight-based pruning\u304C\u6700\u512A: MMLU 80% (-1pp), LiveCodeBench Easy 83.1% (142\u554F)\u3002HuggingFace\u516C\u958B\u6E08\u3002',
      'tech.adapter': 'Expert-as-Adapter',
      'tech.adapter.desc': 'pruning\u3067\u7A7A\u3044\u305Fexpert\u30B9\u30ED\u30C3\u30C8\u3092\u30C9\u30E1\u30A4\u30F3\u30A2\u30C0\u30D7\u30BF\u306B\u5909\u63DB\u3002MoE\u30A2\u30FC\u30AD\u30C6\u30AF\u30C1\u30E3\u81EA\u4F53\u3092\u6D3B\u7528\u3057\u305FLoRA\u4EE3\u66FF \u2014 \u5916\u90E8\u30E2\u30B8\u30E5\u30FC\u30EB\u4E0D\u8981\u3001\u30EB\u30FC\u30BF\u30FC\u3068\u30CD\u30A4\u30C6\u30A3\u30D6\u7D71\u5408\u3002',
      'cta.title': 'MacBook\u3067\u751F\u307E\u308C\u305F\u7814\u7A76\u3002\u3042\u306A\u305F\u306E\u652F\u63F4\u3067\u52A0\u901F\u3059\u308B\u3002',
      'cta.detail': '\u3053\u306E\u7814\u7A76\u306E\u3059\u3079\u3066 \u2014 29\u4EE5\u4E0A\u306E\u30D5\u30A7\u30FC\u30BA\u30016\u30E2\u30C7\u30EB\u30D5\u30A1\u30DF\u30EA\u30FC\u30018\u516C\u958B\u30E2\u30C7\u30EB\u3001100\u4EE5\u4E0A\u306E\u5B9F\u9A13 \u2014 \u306F1\u53F0\u306EMacBook Pro\uFF08M4 Pro\u300124GB RAM\u3001512GB SSD\uFF09\u3067\u5B9F\u65BD\u3055\u308C\u307E\u3057\u305F\u3002\u30C7\u30FC\u30BF\u30BB\u30F3\u30BF\u30FC\u306A\u3057\u3002\u4F01\u696D\u8CC7\u91D1\u306A\u3057\u3002',
      'cta.funding': '\u3054\u652F\u63F4\u306F\u3088\u308A\u5927\u304D\u306A\u30E2\u30C7\u30EB\u3067\u306E\u30C6\u30B9\u30C8\u7528GPU\u3001\u5305\u62EC\u7684\u306A\u30D9\u30F3\u30C1\u30DE\u30FC\u30AF\u7528\u30AF\u30E9\u30A6\u30C9\u30B3\u30F3\u30D4\u30E5\u30FC\u30C8\u3001\u305D\u3057\u3066\u30AA\u30FC\u30D7\u30F3\u30BD\u30FC\u30B9\u7814\u7A76\u3092\u7D9A\u3051\u308B\u6642\u9593\u306B\u76F4\u63A5\u5145\u3066\u3089\u308C\u307E\u3059\u3002',
      'cta.button': 'Ko-fi\u3067\u652F\u63F4',
      'footer.name': 'GOBA-AI-Labs',
    },
    'zh-CN': {
      'nav.models': '\u6A21\u578B',
      'nav.technology': '\u6280\u672F',
      'nav.huggingface': 'HuggingFace',
      'nav.support': '\u652F\u6301\u6211\u4EEC',
      'hero.title': '\u4E13\u5BB6\u51CF\u534A\u3002<br>\u8D28\u91CF\u4E0D\u53D8\u3002',
      'hero.subtitle': '\u6211\u4EEC\u79FB\u9664MoE\u6A21\u578B\u591A\u8FBE50%\u7684\u4E13\u5BB6\uFF0C\u540C\u65F6\u4FDD\u6301\u57FA\u51C6\u6D4B\u8BD5\u5206\u6570\u3002\u5DF2\u5728\u6700\u5927 80B \u6A21\u578B\u4E0A\u9A8C\u8BC1 \u2014 \u76EE\u6807\u662F\u8BA9400B+\u6A21\u578B\u5728\u6D88\u8D39\u7EA7\u786C\u4EF6\u4E0A\u8FD0\u884C\u3002',
      'hero.browse': '\u6D4F\u89C8\u6A21\u578B',
      'hero.huggingface': 'HuggingFace',
      'hero.stat': 'Qwen3.5-35B-A3B \u2014 20% expert pruning, MMLU 80%, fits 24GB Mac GPU',
      'nav.tools': '\u5DE5\u5177',
      'nav.paper': '\u8BBA\u6587',
      'models.title': 'PrunedHub \u6A21\u578B',
      'models.desc': '8\u4E2Apruned MoE\u6A21\u578B\u3002\u5168\u90E8\u652F\u6301llama.cpp\u3002Qwen3/3.5\u4E5F\u53EF\u4EE5\u7528moe-stream\u3002',
      'model.new': 'NEW',
      'model.mxmoe': 'MxMoE',
      'model.qwen35.desc': 'DeltaNet\u6DF7\u5408\u67B6\u6784\uFF0C256 experts\u3002\u53D1\u5E0324\u5C0F\u65F6\u5185\u5B8C\u6210pruning\u300224GB Mac\u5168GPU\u5E38\u9A7B\u3002MMLU -1pp\u3002',
      'model.enmxmoe.desc': 'EN\u4F18\u5316pruning + \u6DF7\u5408\u91CF\u5316 (Q5K/Q4K/Q3K)\u3002-22%\u5927\u5C0F\uFF0CGSM8K 94%\u3002',
      'model.jpmxmoe.desc': 'JA\u8BED\u8A00\u611F\u77E5pruning + MxMoE\u3002GSM8K 96%\uFF0C\u65E5\u8BED\u8D28\u91CF\u4FDD\u7559\u3002',
      'tools.title': '\u63A8\u7406\u5DE5\u5177',
      'tools.desc': '\u5728\u6D88\u8D39\u7EA7\u786C\u4EF6\u4E0A\u8FD0\u884C\u526A\u679D\u540E\u7684MoE\u6A21\u578B\u3002',
      'tools.moestream.tagline': '\u9762\u5411Apple Silicon\u3001CUDA\u548CLinux\u7684SSD\u6D41\u5F0FMoE\u63A8\u7406\u5F15\u64CE',
      'tools.moestream.ssd': '\u4EC5\u97004GB RAM\u5373\u53EF\u8FD0\u884C80B\u6A21\u578B\uFF08NVMe SSD\u6D41\u5F0F\u52A0\u8F7D\uFF09',
      'tools.moestream.adaptive': '\u5C42\u81EA\u9002\u5E94\u526A\u679D\u652F\u6301\uFF08experts_per_layer\uFF09',
      'tools.moestream.speed': 'Q4\u91CF\u5316matmul \u2014 +79%\u52A0\u901F',
      'tools.moestream.metal': 'Metal GPU + CUDA + CPU\u6DF7\u5408\u63A8\u7406',
      'tools.moestream.cicd': 'CI/CD\u548CmacOS/Linux\u9884\u6784\u5EFA\u4E8C\u8FDB\u5236\u6587\u4EF6',
      'tools.moestream.python': 'Python\u7ED1\u5B9A (PyO3)',
      'tools.moestream.github': '\u5728GitHub\u67E5\u770B',
      'model.lossless': '\u65E0\u635F',
      'model.50pruned': '50% \u526A\u51CF',
      'model.japanese': '\u65E5\u8BED',
      'model.experimental': '\u5B9E\u9A8C\u6027',
      'model.gptoss28.desc': '所有基准测试零质量损失。MMLU 78%、HumanEval 78%、GSM8K 92%。适合16GB RAM。',
      'model.qwen80b.desc': '80B模型压缩至24GB。MMLU 72%。44%剪枝（27.7 GB）时：LCB Easy 83%、HumanEval 72%。',
      'model.jp30b.desc': '\u8BED\u8A00\u611F\u77E5\u526A\u679D\u4FDD\u7559\u65E5\u8BED\u8D28\u91CF\u3002Thinking-ON: MMLU 79%, JA 90%\u3002',
      'model.zerobias.desc': '\u8DEF\u7531\u5668\u4F18\u5316\u5728\u526A\u679D\u60AC\u5D16\u5904\u6062\u590D\u8D28\u91CF\u3002\u4E13\u5BB6\u51CF\u5C1115.6%\uFF0C\u4EC5-1pp\u3002',
      'tech.title': '\u5DE5\u4F5C\u539F\u7406',
      'tech.desc': '\u4E13\u5BB6\u526A\u679D\uFF0C\u800C\u975E\u6FC0\u8FDB\u91CF\u5316\u3002',
      'tech.calibration': '\u57FA\u4E8E\u6821\u51C6\u7684\u8BC4\u5206',
      'tech.calibration.desc': '\u901A\u8FC7\u591A\u6837\u5316\u5DE5\u4F5C\u8D1F\u8F7D\u7684\u5B9E\u9645\u63A8\u7406\u6765\u8861\u91CF\u4E13\u5BB6\u91CD\u8981\u6027\u3002\u6BD4\u9759\u6001\u6743\u91CD\u5206\u6790\u7CBE\u786E\u5F97\u591A\u3002',
      'tech.adaptive': '\u5C42\u81EA\u9002\u5E94\u5206\u914D',
      'tech.adaptive.desc': '\u6BCF\u5C42\u52A8\u6001\u4FDD\u7559\u4E0D\u540C\u6570\u91CF\u7684\u4E13\u5BB6\u3002\u5BF9\u526A\u679D\u654F\u611F\u7684\u5C42\u4F18\u5148\u4FDD\u6301\u8D28\u91CF\u3002',
      'tech.language': '\u8BED\u8A00\u611F\u77E5\u4F18\u5316',
      'tech.language.desc': '\u81EA\u52A8\u68C0\u6D4B\u5E76\u4FDD\u62A4\u8BED\u8A00\u4E13\u4E1A\u4E13\u5BB6\u3002\u538B\u7F29\u65F6\u4FDD\u7559\u65E5\u8BED\u3001\u4E2D\u6587\u7B49\u8BED\u8A00\u80FD\u529B\u3002',
      'tech.zerobias': 'Zerobias\u8DEF\u7531\u4F18\u5316',
      'tech.zerobias.desc': '\u526A\u679D\u540E\u7684\u8DEF\u7531\u5668\u504F\u7F6E\u6821\u6B63\u6269\u5C55\u4E86\u65E0\u635F\u538B\u7F29\u7684\u8FB9\u754C\u3002\u96F6\u6210\u672C\uFF0C\u65E0\u9700\u91CD\u65B0\u8BAD\u7EC3\u3002',
      'comp.title': '\u4E13\u5BB6\u526A\u679D vs \u91CF\u5316',
      'comp.pruning': '\u4E13\u5BB6\u526A\u679D',
      'comp.quantization': 'Q2\u91CF\u5316',
      'comp.approach': '\u65B9\u6CD5',
      'comp.pruning.approach': '\u5B8C\u5168\u79FB\u9664\u5197\u4F59\u4E13\u5BB6',
      'comp.quant.approach': '\u964D\u4F4E\u6240\u6709\u6743\u91CD\u7684\u7CBE\u5EA6',
      'comp.quality': '\u8D28\u91CF\u5F71\u54CD',
      'comp.pruning.quality': '\u6709\u9488\u5BF9\u6027\uFF0C\u5F71\u54CD\u6700\u5C0F',
      'comp.quant.quality': '\u5747\u5300\u9000\u5316',
      'comp.24gb': '~24 GB\u6A21\u578B\u8D28\u91CF',
      'comp.pruning.24gb': 'MMLU 72%',
      'comp.quant.24gb': 'MMLU ~55\u201360%',
      'comp.precision': '\u6B8B\u4F59\u7CBE\u5EA6',
      'comp.pruning.precision': 'Q4\u5168\u7CBE\u5EA6',
      'comp.quant.precision': '2\u4F4D\u7CBE\u5EA6',
      'vision.title': '未来展望',
      'vision.desc': '专家剪枝只是开始。以下是即将成为可能的事情。',
      'vision.hardware': '消费级硬件',
      'vision.hardware.desc': '在24GB RAM的笔记本电脑上运行前沿MoE模型 \u2014 无需万元级服务器GPU。让最强AI触手可及。',
      'vision.energy': '更低能耗',
      'vision.energy.desc': '更少的专家意味着每个token更少的计算量。数据中心可以用一半的算力提供同等质量 \u2014 大规模节能。',
      'vision.rl': '剪枝后强化学习',
      'vision.rl.desc': '剪枝模型为定向强化学习创造了空间。相同大小，可能更好的性能 \u2014 不仅是质量保持，更是质量提升。',
      'vision.edge': '边缘部署',
      'vision.edge.desc': 'MoE模型可在设备端推理中实际使用。私密、快速、离线 \u2014 将专家级AI带到手机和嵌入式系统。',
      'models.goba.title': 'GOBA \u6A21\u578B',
      'models.goba.desc': '\u4F7F\u7528Expert-as-Adapter\u6280\u672F\u7684\u9886\u57DF\u7279\u5316\u6A21\u578B\u3002\u526A\u679D\u540E\u7684\u7A7A\u95F2expert\u69FD\u4F4D\u88AB\u91CD\u65B0\u7528\u4E8E\u4E13\u4E1A\u5316\u3002',
      'model.experttuned': 'Expert\u8C03\u4F18',
      'model.olmoe.domains': '\u9886\u57DF',
      'model.olmoe.desc': '\u901A\u8FC7Expert-as-Adapter\u76843\u4E2A\u9886\u57DF\u7279\u5316\u53D8\u4F53\u3002JA +4.5pp JMMLU\u3001Code +10pp HumanEval+\u3001Finance +16pp\u6B3A\u8BC8\u68C0\u6D4B\u3002',
      'models.research.title': '\u7814\u7A76\u4EAE\u70B9',
      'models.research.80b': '80B\u4EE3\u7801\u751F\u6210\u53D1\u73B0',
      'models.research.80b.desc': '50% expert\u526A\u679D\u4FDD\u6301MMLU 76%\u4F46\u7834\u574F\u4EE3\u7801\u751F\u6210\uFF08HumanEval 0%\uFF09\u3002\u4EE3\u7801\u751F\u6210\u4F7F\u7528\u4E8684%\u7684expert \u2014 \u4E00\u79CD\u62B5\u6297\u526A\u679D\u7684\u5206\u5E03\u5F0F\u80FD\u529B\u3002',
      'models.research.qwen35': 'Qwen3.5-35B-A3B: Day-1 Pruning',
      'models.research.qwen35.desc': '\u53D1\u5E0324\u5C0F\u65F6\u5185\u5B8C\u6210pruning\u3002\u5728256 expert DeltaNet\u6DF7\u5408\u67B6\u6784\u4E0A\u6BD4\u8F835\u79CD\u65B9\u6CD5\u3002Weight-based pruning\u6700\u4F18: MMLU 80% (-1pp), LiveCodeBench Easy 83.1% (142\u9898)\u3002\u5DF2\u53D1\u5E03\u5230HuggingFace\u3002',
      'tech.adapter': 'Expert-as-Adapter',
      'tech.adapter.desc': '\u526A\u679D\u540E\u7684\u7A7A\u95F2expert\u69FD\u4F4D\u53D8\u6210\u9886\u57DF\u9002\u914D\u5668\u3002\u5229\u7528MoE\u67B6\u6784\u672C\u8EAB\u7684LoRA\u66FF\u4EE3\u65B9\u6848 \u2014 \u65E0\u9700\u5916\u90E8\u6A21\u5757\uFF0C\u4E0E\u8DEF\u7531\u5668\u539F\u751F\u96C6\u6210\u3002',
      'cta.title': '\u8BDE\u751F\u4E8EMacBook\u3002\u7531\u4F60\u8D44\u52A9\u3002',
      'cta.detail': '\u8FD9\u9879\u7814\u7A76\u7684\u5168\u90E8 \u2014 29\u4E2A\u4EE5\u4E0A\u9636\u6BB5\u30016\u4E2A\u6A21\u578B\u5BB6\u65CF\u30018\u4E2A\u5DF2\u53D1\u5E03\u6A21\u578B\u3001100\u591A\u6B21\u5B9E\u9A8C \u2014 \u5728\u4E00\u53F0MacBook Pro\uFF08M4 Pro\u300124GB RAM\u3001512GB SSD\uFF09\u4E0A\u5B8C\u6210\u3002\u6CA1\u6709\u6570\u636E\u4E2D\u5FC3\u3002\u6CA1\u6709\u4F01\u4E1A\u8D44\u52A9\u3002',
      'cta.funding': '\u60A8\u7684\u652F\u6301\u76F4\u63A5\u7528\u4E8E\uFF1A\u5728\u66F4\u5927\u6A21\u578B\u4E0A\u6D4B\u8BD5\u7684GPU\u8D44\u6E90\u3001\u5168\u9762\u57FA\u51C6\u6D4B\u8BD5\u7684\u4E91\u8BA1\u7B97\uFF0C\u4EE5\u53CA\u7EE7\u7EED\u5F00\u6E90\u7814\u7A76\u7684\u65F6\u95F4\u3002',
      'cta.button': '\u5728Ko-fi\u4E0A\u652F\u6301',
      'footer.name': 'GOBA-AI-Labs',
    },
    'zh-TW': {
      'nav.models': '\u6A21\u578B',
      'nav.technology': '\u6280\u8853',
      'nav.huggingface': 'HuggingFace',
      'nav.support': '\u652F\u6301\u6211\u5011',
      'hero.title': '\u5C08\u5BB6\u6E1B\u534A\u3002<br>\u54C1\u8CEA\u4E0D\u8B8A\u3002',
      'hero.subtitle': '\u6211\u5011\u79FB\u9664MoE\u6A21\u578B\u591A\u905450%\u7684\u5C08\u5BB6\uFF0C\u540C\u6642\u4FDD\u6301\u57FA\u6E96\u6E2C\u8A66\u5206\u6578\u3002\u5DF2\u5728\u6700\u5927 80B \u6A21\u578B\u4E0A\u9A57\u8B49 \u2014 \u76EE\u6A19\u662F\u8B93400B+\u6A21\u578B\u5728\u6D88\u8CBB\u7D1A\u786C\u9AD4\u4E0A\u904B\u884C\u3002',
      'hero.browse': '\u700F\u89BD\u6A21\u578B',
      'hero.huggingface': 'HuggingFace',
      'hero.stat': 'Qwen3.5-35B-A3B \u2014 20% expert pruning, MMLU 80%, fits 24GB Mac GPU',
      'nav.tools': '\u5DE5\u5177',
      'nav.paper': '\u8AD6\u6587',
      'models.title': 'PrunedHub \u6A21\u578B',
      'models.desc': '8\u500Bpruned MoE\u6A21\u578B\u3002\u5168\u90E8\u652F\u63F4llama.cpp\u3002Qwen3/3.5\u4E5F\u53EF\u4EE5\u7528moe-stream\u3002',
      'model.new': 'NEW',
      'model.mxmoe': 'MxMoE',
      'model.qwen35.desc': 'DeltaNet\u6DF7\u5408\u67B6\u69CB\uFF0C256 experts\u3002\u767C\u5E0324\u5C0F\u6642\u5167\u5B8C\u6210pruning\u300224GB Mac\u5168GPU\u5E38\u99D0\u3002MMLU -1pp\u3002',
      'model.enmxmoe.desc': 'EN\u512A\u5316pruning + \u6DF7\u5408\u91CF\u5316 (Q5K/Q4K/Q3K)\u3002-22%\u5927\u5C0F\uFF0CGSM8K 94%\u3002',
      'model.jpmxmoe.desc': 'JA\u8A9E\u8A00\u611F\u77E5pruning + MxMoE\u3002GSM8K 96%\uFF0C\u65E5\u8A9E\u54C1\u8CEA\u4FDD\u7559\u3002',
      'tools.title': '\u63A8\u7406\u5DE5\u5177',
      'tools.desc': '\u5728\u6D88\u8CBB\u7D1A\u786C\u9AD4\u4E0A\u57F7\u884C\u526A\u679D\u5F8C\u7684MoE\u6A21\u578B\u3002',
      'tools.moestream.tagline': '\u9762\u5411Apple Silicon\u3001CUDA\u548CLinux\u7684SSD\u6D41\u5F0FMoE\u63A8\u7406\u5F15\u64CE',
      'tools.moestream.ssd': '\u50C54GB RAM\u5373\u53EF\u57F7\u884C80B\u6A21\u578B\uFF08NVMe SSD\u6D41\u5F0F\u8F09\u5165\uFF09',
      'tools.moestream.adaptive': '\u5C64\u81EA\u9069\u61C9\u526A\u679D\u652F\u63F4\uFF08experts_per_layer\uFF09',
      'tools.moestream.speed': 'Q4\u91CF\u5316matmul \u2014 +79%\u52A0\u901F',
      'tools.moestream.metal': 'Metal GPU + CUDA + CPU\u6DF7\u5408\u63A8\u7406',
      'tools.moestream.cicd': 'CI/CD\u548CmacOS/Linux\u9810\u69CB\u5EFA\u4E8C\u9032\u4F4D\u6A94\u6848',
      'tools.moestream.python': 'Python\u7D81\u5B9A (PyO3)',
      'tools.moestream.github': '\u5728GitHub\u67E5\u770B',
      'model.lossless': '\u7121\u640D',
      'model.50pruned': '50% \u524A\u6E1B',
      'model.japanese': '\u65E5\u8A9E',
      'model.experimental': '\u5BE6\u9A57\u6027',
      'model.gptoss28.desc': '所有基準測試零品質損失。MMLU 78%、HumanEval 78%、GSM8K 92%。適合16GB RAM。',
      'model.qwen80b.desc': '80B模型壓縮至24GB。MMLU 72%。44%剪枝（27.7 GB）時：LCB Easy 83%、HumanEval 72%。',
      'model.jp30b.desc': '\u8A9E\u8A00\u611F\u77E5\u526A\u679D\u4FDD\u7559\u65E5\u8A9E\u54C1\u8CEA\u3002Thinking-ON: MMLU 79%, JA 90%\u3002',
      'model.zerobias.desc': '\u8DEF\u7531\u5668\u512A\u5316\u5728\u526A\u679D\u61F8\u5D16\u8655\u6062\u5FA9\u54C1\u8CEA\u3002\u5C08\u5BB6\u6E1B\u5C1115.6%\uFF0C\u50C5-1pp\u3002',
      'tech.title': '\u5DE5\u4F5C\u539F\u7406',
      'tech.desc': '\u5C08\u5BB6\u526A\u679D\uFF0C\u800C\u975E\u6FC0\u9032\u91CF\u5316\u3002',
      'tech.calibration': '\u57FA\u65BC\u6821\u6E96\u7684\u8A55\u5206',
      'tech.calibration.desc': '\u900F\u904E\u591A\u6A23\u5316\u5DE5\u4F5C\u8CA0\u8F09\u7684\u5BE6\u969B\u63A8\u7406\u4F86\u8861\u91CF\u5C08\u5BB6\u91CD\u8981\u6027\u3002\u6BD4\u975C\u614B\u6B0A\u91CD\u5206\u6790\u7CBE\u78BA\u5F97\u591A\u3002',
      'tech.adaptive': '\u5C64\u81EA\u9069\u61C9\u5206\u914D',
      'tech.adaptive.desc': '\u6BCF\u5C64\u52D5\u614B\u4FDD\u7559\u4E0D\u540C\u6578\u91CF\u7684\u5C08\u5BB6\u3002\u5C0D\u526A\u679D\u654F\u611F\u7684\u5C64\u512A\u5148\u4FDD\u6301\u54C1\u8CEA\u3002',
      'tech.language': '\u8A9E\u8A00\u611F\u77E5\u512A\u5316',
      'tech.language.desc': '\u81EA\u52D5\u6AA2\u6E2C\u4E26\u4FDD\u8B77\u8A9E\u8A00\u5C08\u696D\u5C08\u5BB6\u3002\u58D3\u7E2E\u6642\u4FDD\u7559\u65E5\u8A9E\u3001\u4E2D\u6587\u7B49\u8A9E\u8A00\u80FD\u529B\u3002',
      'tech.zerobias': 'Zerobias\u8DEF\u7531\u512A\u5316',
      'tech.zerobias.desc': '\u526A\u679D\u5F8C\u7684\u8DEF\u7531\u5668\u504F\u7F6E\u6821\u6B63\u64F4\u5C55\u4E86\u7121\u640D\u58D3\u7E2E\u7684\u908A\u754C\u3002\u96F6\u6210\u672C\uFF0C\u7121\u9700\u91CD\u65B0\u8A13\u7DF4\u3002',
      'comp.title': '\u5C08\u5BB6\u526A\u679D vs \u91CF\u5316',
      'comp.pruning': '\u5C08\u5BB6\u526A\u679D',
      'comp.quantization': 'Q2\u91CF\u5316',
      'comp.approach': '\u65B9\u6CD5',
      'comp.pruning.approach': '\u5B8C\u5168\u79FB\u9664\u5197\u9918\u5C08\u5BB6',
      'comp.quant.approach': '\u964D\u4F4E\u6240\u6709\u6B0A\u91CD\u7684\u7CBE\u5EA6',
      'comp.quality': '\u54C1\u8CEA\u5F71\u97FF',
      'comp.pruning.quality': '\u6709\u91DD\u5C0D\u6027\uFF0C\u5F71\u97FF\u6700\u5C0F',
      'comp.quant.quality': '\u5747\u52FB\u9000\u5316',
      'comp.24gb': '~24 GB\u6A21\u578B\u54C1\u8CEA',
      'comp.pruning.24gb': 'MMLU 72%',
      'comp.quant.24gb': 'MMLU ~55\u201360%',
      'comp.precision': '\u6B98\u9918\u7CBE\u5EA6',
      'comp.pruning.precision': 'Q4\u5168\u7CBE\u5EA6',
      'comp.quant.precision': '2\u4F4D\u5143\u7CBE\u5EA6',
      'vision.title': '未來展望',
      'vision.desc': '專家剪枝只是開始。以下是即將成為可能的事情。',
      'vision.hardware': '消費級硬體',
      'vision.hardware.desc': '在24GB RAM的筆記型電腦上執行前沿MoE模型 \u2014 無需萬元級伺服器GPU。讓最強AI觸手可及。',
      'vision.energy': '更低能耗',
      'vision.energy.desc': '更少的專家意味著每個token更少的計算量。資料中心可以用一半的算力提供同等品質 \u2014 大規模節能。',
      'vision.rl': '剪枝後強化學習',
      'vision.rl.desc': '剪枝模型為定向強化學習創造了空間。相同大小，可能更好的效能 \u2014 不僅是品質保持，更是品質提升。',
      'vision.edge': '邊緣部署',
      'vision.edge.desc': 'MoE模型可在裝置端推理中實際使用。私密、快速、離線 \u2014 將專家級AI帶到手機和嵌入式系統。',
      'models.goba.title': 'GOBA \u6A21\u578B',
      'models.goba.desc': '\u4F7F\u7528Expert-as-Adapter\u6280\u8853\u7684\u9818\u57DF\u7279\u5316\u6A21\u578B\u3002\u526A\u679D\u5F8C\u7684\u7A7A\u9592expert\u69FD\u4F4D\u88AB\u91CD\u65B0\u7528\u65BC\u5C08\u696D\u5316\u3002',
      'model.experttuned': 'Expert\u8ABF\u512A',
      'model.olmoe.domains': '\u9818\u57DF',
      'model.olmoe.desc': '\u900F\u904EExpert-as-Adapter\u76843\u500B\u9818\u57DF\u7279\u5316\u8B8A\u9AD4\u3002JA +4.5pp JMMLU\u3001Code +10pp HumanEval+\u3001Finance +16pp\u8A50\u6B3A\u6AA2\u6E2C\u3002',
      'models.research.title': '\u7814\u7A76\u4EAE\u9EDE',
      'models.research.80b': '80B\u7A0B\u5F0F\u78BC\u751F\u6210\u767C\u73FE',
      'models.research.80b.desc': '50% expert\u526A\u679D\u4FDD\u6301MMLU 76%\u4F46\u7834\u58DE\u7A0B\u5F0F\u78BC\u751F\u6210\uFF08HumanEval 0%\uFF09\u3002\u7A0B\u5F0F\u78BC\u751F\u6210\u4F7F\u752884%\u7684expert \u2014 \u4E00\u7A2E\u62B5\u6297\u526A\u679D\u7684\u5206\u6563\u5F0F\u80FD\u529B\u3002',
      'models.research.qwen35': 'Qwen3.5-35B-A3B: Day-1 Pruning',
      'models.research.qwen35.desc': '\u767C\u5E0324\u5C0F\u6642\u5167\u5B8C\u6210pruning\u3002\u5728256 expert DeltaNet\u6DF7\u5408\u67B6\u69CB\u4E0A\u6BD4\u8F035\u7A2E\u65B9\u6CD5\u3002Weight-based pruning\u6700\u512A: MMLU 80% (-1pp), LiveCodeBench Easy 83.1% (142\u984C)\u3002\u5DF2\u767C\u5E03\u5230HuggingFace\u3002',
      'tech.adapter': 'Expert-as-Adapter',
      'tech.adapter.desc': '\u526A\u679D\u5F8C\u7684\u7A7A\u9592expert\u69FD\u4F4D\u8B8A\u6210\u9818\u57DF\u9069\u914D\u5668\u3002\u5229\u7528MoE\u67B6\u69CB\u672C\u8EAB\u7684LoRA\u66FF\u4EE3\u65B9\u6848 \u2014 \u7121\u9700\u5916\u90E8\u6A21\u7D44\uFF0C\u8207\u8DEF\u7531\u5668\u539F\u751F\u6574\u5408\u3002',
      'cta.title': '\u8A95\u751F\u65BCMacBook\u3002\u7531\u4F60\u8CC7\u52A9\u3002',
      'cta.detail': '\u9019\u9805\u7814\u7A76\u7684\u5168\u90E8 \u2014 29\u500B\u4EE5\u4E0A\u968E\u6BB5\u30016\u500B\u6A21\u578B\u5BB6\u65CF\u30018\u500B\u5DF2\u767C\u5E03\u6A21\u578B\u3001100\u591A\u6B21\u5BE6\u9A57 \u2014 \u5728\u4E00\u53F0MacBook Pro\uFF08M4 Pro\u300124GB RAM\u3001512GB SSD\uFF09\u4E0A\u5B8C\u6210\u3002\u6C92\u6709\u8CC7\u6599\u4E2D\u5FC3\u3002\u6C92\u6709\u4F01\u696D\u8CC7\u52A9\u3002',
      'cta.funding': '\u60A8\u7684\u652F\u6301\u76F4\u63A5\u7528\u65BC\uFF1A\u5728\u66F4\u5927\u6A21\u578B\u4E0A\u6E2C\u8A66\u7684GPU\u8CC7\u6E90\u3001\u5168\u9762\u57FA\u6E96\u6E2C\u8A66\u7684\u96F2\u7AEF\u904B\u7B97\uFF0C\u4EE5\u53CA\u7E7C\u7E8C\u958B\u6E90\u7814\u7A76\u7684\u6642\u9593\u3002',
      'cta.button': '\u5728Ko-fi\u4E0A\u652F\u6301',
      'footer.name': 'GOBA-AI-Labs',
    },
    ko: {
      'nav.models': '\uBAA8\uB378',
      'nav.technology': '\uAE30\uC220',
      'nav.huggingface': 'HuggingFace',
      'nav.support': '\uD6C4\uC6D0\uD558\uAE30',
      'hero.title': '\uC804\uBB38\uAC00 \uC808\uBC18.<br>\uD488\uC9C8 \uADF8\uB300\uB85C.',
      'hero.subtitle': 'MoE \uBAA8\uB378\uC758 \uC804\uBB38\uAC00\uB97C \uCD5C\uB300 50% \uC81C\uAC70\uD558\uBA74\uC11C \uBCA4\uCE58\uB9C8\uD06C \uC810\uC218\uB97C \uC720\uC9C0\uD569\uB2C8\uB2E4. \uCD5C\uB300 80B \uBAA8\uB378\uC5D0\uC11C \uAC80\uC99D \uC644\uB8CC \u2014 \uBAA9\uD45C\uB294 400B+ \uBAA8\uB378\uC744 \uC18C\uBE44\uC790 \uD558\uB4DC\uC6E8\uC5B4\uC5D0\uC11C \uC2E4\uD589\uD558\uB294 \uAC83\uC785\uB2C8\uB2E4.',
      'hero.browse': '\uBAA8\uB378 \uBCF4\uAE30',
      'hero.huggingface': 'HuggingFace',
      'hero.stat': 'Qwen3.5-35B-A3B \u2014 20% expert pruning, MMLU 80%, fits 24GB Mac GPU',
      'nav.tools': '\uB3C4\uAD6C',
      'nav.paper': '\uB17C\uBB38',
      'models.title': 'PrunedHub \uBAA8\uB378',
      'models.desc': '8\uAC1C\uC758 pruned MoE \uBAA8\uB378. \uBAA8\uB450 llama.cpp \uD638\uD658. Qwen3/3.5\uB294 moe-stream\uC73C\uB85C\uB3C4 \uC2E4\uD589 \uAC00\uB2A5.',
      'model.new': 'NEW',
      'model.mxmoe': 'MxMoE',
      'model.qwen35.desc': 'DeltaNet \uD558\uC774\uBE0C\uB9AC\uB4DC, 256 experts. \uCD9C\uC2DC 24\uC2DC\uAC04 \uB0B4 pruning \uC644\uB8CC. 24GB Mac\uC5D0\uC11C \uC804\uCCB4 GPU \uC0C1\uC8FC. MMLU -1pp.',
      'model.enmxmoe.desc': 'EN \uCD5C\uC801\uD654 pruning + \uD63C\uD569 \uC591\uC790\uD654 (Q5K/Q4K/Q3K). -22% \uD06C\uAE30, GSM8K 94%.',
      'model.jpmxmoe.desc': 'JA \uC5B8\uC5B4 \uC778\uC2DD pruning + MxMoE. GSM8K 96%, \uC77C\uBCF8\uC5B4 \uD488\uC9C8 \uC720\uC9C0.',
      'tools.title': '\uCD94\uB860 \uB3C4\uAD6C',
      'tools.desc': '\uC18C\uBE44\uC790 \uD558\uB4DC\uC6E8\uC5B4\uC5D0\uC11C \uD504\uB8E8\uB2DD\uB41C MoE \uBAA8\uB378\uC744 \uC2E4\uD589.',
      'tools.moestream.tagline': 'Apple Silicon\u30FBCUDA\u30FBLinux\uC6A9 SSD \uC2A4\uD2B8\uB9AC\uBC0D MoE \uCD94\uB860 \uC5D4\uC9C4',
      'tools.moestream.ssd': '4GB RAM\uC73C\uB85C 80B \uBAA8\uB378 \uC2E4\uD589 (NVMe SSD \uC2A4\uD2B8\uB9AC\uBC0D)',
      'tools.moestream.adaptive': '\uB808\uC774\uC5B4 \uC801\uC751\uD615 \uD504\uB8E8\uB2DD \uC9C0\uC6D0 (experts_per_layer)',
      'tools.moestream.speed': 'Q4 \uC591\uC790\uD654 matmul \u2014 +79% \uC18D\uB3C4 \uD5A5\uC0C1',
      'tools.moestream.metal': 'Metal GPU + CUDA + CPU \uD558\uC774\uBE0C\uB9AC\uB4DC \uCD94\uB860',
      'tools.moestream.cicd': 'CI/CD \uBC0F macOS/Linux \uC0AC\uC804 \uBE4C\uB4DC \uBC14\uC774\uB108\uB9AC',
      'tools.moestream.python': 'Python \uBC14\uC778\uB529 (PyO3)',
      'tools.moestream.github': 'GitHub\uC5D0\uC11C \uBCF4\uAE30',
      'model.lossless': '\uBB34\uC190\uC2E4',
      'model.50pruned': '50% \uC0AD\uAC10',
      'model.japanese': '\uC77C\uBCF8\uC5B4',
      'model.experimental': '\uC2E4\uD5D8\uC801',
      'model.gptoss28.desc': '모든 벤치마크에서 품질 손실 제로. MMLU 78%, HumanEval 78%, GSM8K 92%. 16GB RAM에 수용.',
      'model.qwen80b.desc': '80B 모델을 24GB로 압축. MMLU 72%. 44% 프루닝 (27.7 GB) 시: LCB Easy 83%, HumanEval 72%.',
      'model.jp30b.desc': '\uC5B8\uC5B4 \uC778\uC2DD \uD504\uB8E8\uB2DD\uC73C\uB85C \uC77C\uBCF8\uC5B4 \uD488\uC9C8 \uC720\uC9C0. Thinking-ON: MMLU 79%, JA 90%.',
      'model.zerobias.desc': '\uB77C\uC6B0\uD130 \uCD5C\uC801\uD654\uB85C \uD504\uB8E8\uB2DD \uD074\uB9AC\uD504\uC5D0\uC11C \uD488\uC9C8 \uBCF5\uAD6C. \uC804\uBB38\uAC00 15.6% \uAC10\uC18C\uB85C -1pp.',
      'tech.title': '\uC791\uB3D9 \uC6D0\uB9AC',
      'tech.desc': '\uACF5\uACA9\uC801\uC778 \uC591\uC790\uD654\uAC00 \uC544\uB2CC, \uC804\uBB38\uAC00 \uD504\uB8E8\uB2DD.',
      'tech.calibration': '\uCE98\uB9AC\uBE0C\uB808\uC774\uC158 \uAE30\uBC18 \uC2A4\uCF54\uC5B4\uB9C1',
      'tech.calibration.desc': '\uB2E4\uC591\uD55C \uC6CC\uD06C\uB85C\uB4DC\uC5D0\uC11C\uC758 \uC2E4\uC81C \uCD94\uB860\uC744 \uD1B5\uD574 \uC804\uBB38\uAC00 \uC911\uC694\uB3C4\uB97C \uCE21\uC815. \uC815\uC801 \uAC00\uC911\uCE58 \uBD84\uC11D\uBCF4\uB2E4 \uD6E8\uC52C \uC815\uD655.',
      'tech.adaptive': '\uB808\uC774\uC5B4 \uC801\uC751\uD615 \uD560\uB2F9',
      'tech.adaptive.desc': '\uAC01 \uB808\uC774\uC5B4\uAC00 \uB3D9\uC801\uC73C\uB85C \uACB0\uC815\uB41C \uC218\uC758 \uC804\uBB38\uAC00\uB97C \uC720\uC9C0. \uD504\uB8E8\uB2DD\uC5D0 \uBBFC\uAC10\uD55C \uB808\uC774\uC5B4\uC758 \uD488\uC9C8\uC744 \uC6B0\uC120 \uBCF4\uC804.',
      'tech.language': '\uC5B8\uC5B4 \uC778\uC2DD \uCD5C\uC801\uD654',
      'tech.language.desc': '\uC5B8\uC5B4 \uC804\uBB38 \uC804\uBB38\uAC00\uB97C \uC790\uB3D9 \uAC10\uC9C0\uD558\uACE0 \uBCF4\uD638. \uC555\uCD95 \uC2DC \uC77C\uBCF8\uC5B4, \uC911\uAD6D\uC5B4 \uB4F1\uC758 \uC5B8\uC5B4 \uB2A5\uB825\uC744 \uBCF4\uC874.',
      'tech.zerobias': 'Zerobias \uB77C\uC6B0\uD130 \uCD5C\uC801\uD654',
      'tech.zerobias.desc': '\uD504\uB8E8\uB2DD \uD6C4 \uB77C\uC6B0\uD130 \uBC14\uC774\uC5B4\uC2A4 \uBCF4\uC815\uC73C\uB85C \uBB34\uC190\uC2E4 \uC555\uCD95 \uD55C\uACC4\uB97C \uD655\uC7A5. \uBE44\uC6A9 \uC81C\uB85C, \uC7AC\uD559\uC2B5 \uBD88\uD544\uC694.',
      'comp.title': '\uC804\uBB38\uAC00 \uD504\uB8E8\uB2DD vs \uC591\uC790\uD654',
      'comp.pruning': '\uC804\uBB38\uAC00 \uD504\uB8E8\uB2DD',
      'comp.quantization': 'Q2 \uC591\uC790\uD654',
      'comp.approach': '\uC811\uADFC\uBC95',
      'comp.pruning.approach': '\uC911\uBCF5 \uC804\uBB38\uAC00\uB97C \uC644\uC804\uD788 \uC81C\uAC70',
      'comp.quant.approach': '\uBAA8\uB4E0 \uAC00\uC911\uCE58\uC758 \uC815\uBC00\uB3C4 \uAC10\uC18C',
      'comp.quality': '\uD488\uC9C8 \uC601\uD5A5',
      'comp.pruning.quality': '\uD0C0\uAC9F\uD615, \uCD5C\uC18C\uD55C\uC758 \uC601\uD5A5',
      'comp.quant.quality': '\uADE0\uC77C\uD55C \uC800\uD558',
      'comp.24gb': '~24 GB \uBAA8\uB378 \uD488\uC9C8',
      'comp.pruning.24gb': 'MMLU 72%',
      'comp.quant.24gb': 'MMLU ~55\u201360%',
      'comp.precision': '\uC794\uC5EC \uC815\uBC00\uB3C4',
      'comp.pruning.precision': 'Q4 \uC804\uCCB4 \uC815\uBC00\uB3C4',
      'comp.quant.precision': '2\uBE44\uD2B8 \uC815\uBC00\uB3C4',
      'vision.title': '미래 전망',
      'vision.desc': '전문가 프루닝은 시작에 불과합니다. 앞으로 가능해지는 것들.',
      'vision.hardware': '소비자 하드웨어',
      'vision.hardware.desc': '24GB RAM 노트북에서 최첨단 MoE 모델 실행 \u2014 고가의 서버 GPU 불필요. 가장 강력한 AI에 대한 접근을 민주화.',
      'vision.energy': '낮은 에너지 비용',
      'vision.energy.desc': '더 적은 전문가는 토큰당 더 적은 연산을 의미. 데이터 센터가 절반의 컴퓨팅으로 동일한 품질을 제공 \u2014 대규모 전력 절감.',
      'vision.rl': '프루닝 후 강화학습',
      'vision.rl.desc': '프루닝된 모델은 타겟 강화학습의 여지를 만듭니다. 같은 크기, 잠재적으로 더 나은 성능 \u2014 품질 보존이 아닌 품질 증폭.',
      'vision.edge': '엣지 배포',
      'vision.edge.desc': 'MoE 모델이 온디바이스 추론에서 실용적으로. 프라이빗, 빠르고, 오프라인 \u2014 전문가 수준의 AI를 스마트폰과 임베디드 시스템으로.',
      'models.goba.title': 'GOBA \uBAA8\uB378',
      'models.goba.desc': 'Expert-as-Adapter \uAE30\uC220\uC744 \uC0AC\uC6A9\uD55C \uB3C4\uBA54\uC778 \uD2B9\uD654 \uBAA8\uB378. \uD504\uB8E8\uB2DD\uB41C expert \uC2AC\uB86F\uC744 \uC804\uBB38\uD654\uC5D0 \uC7AC\uD65C\uC6A9.',
      'model.experttuned': 'Expert \uD29C\uB2DD',
      'model.olmoe.domains': '\uB3C4\uBA54\uC778',
      'model.olmoe.desc': 'Expert-as-Adapter\uB97C \uD1B5\uD55C 3\uAC1C \uB3C4\uBA54\uC778 \uD2B9\uD654 \uBCC0\uD615. JA +4.5pp JMMLU, Code +10pp HumanEval+, Finance +16pp \uC0AC\uAE30 \uD0D0\uC9C0.',
      'models.research.title': '\uC5F0\uAD6C \uD558\uC774\uB77C\uC774\uD2B8',
      'models.research.80b': '80B \uCF54\uB4DC \uC0DD\uC131 \uBC1C\uACAC',
      'models.research.80b.desc': '50% expert \uD504\uB8E8\uB2DD\uC73C\uB85C MMLU 76%\uB97C \uC720\uC9C0\uD558\uC9C0\uB9CC \uCF54\uB4DC \uC0DD\uC131\uC740 \uBD95\uAD34 (HumanEval 0%). \uCF54\uB4DC \uC0DD\uC131\uC740 expert\uC758 84%\uB97C \uC0AC\uC6A9 \u2014 \uD504\uB8E8\uB2DD\uC5D0 \uC800\uD56D\uD558\uB294 \uBD84\uC0B0\uD615 \uB2A5\uB825.',
      'models.research.qwen35': 'Qwen3.5-35B-A3B: Day-1 Pruning',
      'models.research.qwen35.desc': '\uCD9C\uC2DC 24\uC2DC\uAC04 \uB0B4 pruning \uC644\uB8CC. 256 expert DeltaNet \uD558\uC774\uBE0C\uB9AC\uB4DC\uC5D0\uC11C 5\uAC00\uC9C0 \uBC29\uBC95 \uBE44\uAD50. Weight-based pruning \uCD5C\uC6B0\uC218: MMLU 80% (-1pp), LiveCodeBench Easy 83.1% (142\uBB38\uC81C). HuggingFace \uACF5\uAC1C \uC644\uB8CC.',
      'tech.adapter': 'Expert-as-Adapter',
      'tech.adapter.desc': '\uD504\uB8E8\uB2DD\uB41C \uBE48 expert \uC2AC\uB86F\uC774 \uB3C4\uBA54\uC778 \uC5B4\uB311\uD130\uB85C \uBCC0\uD658. MoE \uC544\uD0A4\uD14D\uCC98 \uC790\uCCB4\uB97C \uD65C\uC6A9\uD55C LoRA \uB300\uC548 \u2014 \uC678\uBD80 \uBAA8\uB4C8 \uBD88\uD544\uC694, \uB77C\uC6B0\uD130\uC640 \uB124\uC774\uD2F0\uBE0C \uD1B5\uD569.',
      'cta.title': 'MacBook\uC5D0\uC11C \uD0C4\uC0DD. \uC5EC\uB7EC\uBD84\uC774 \uD6C4\uC6D0.',
      'cta.detail': '\uC774 \uC5F0\uAD6C\uC758 \uC804\uBD80 \u2014 29\uB2E8\uACC4 \uC774\uC0C1, 6\uAC1C \uBAA8\uB378 \uD328\uBC00\uB9AC, 8\uAC1C \uACF5\uAC1C \uBAA8\uB378, 100\uD68C \uC774\uC0C1\uC758 \uC2E4\uD5D8 \u2014 \uB294 \uD55C \uB300\uC758 MacBook Pro (M4 Pro, 24GB RAM, 512GB SSD)\uC5D0\uC11C \uC218\uD589\uB418\uC5C8\uC2B5\uB2C8\uB2E4. \uB370\uC774\uD130 \uC13C\uD130 \uC5C6\uC774. \uAE30\uC5C5 \uC790\uAE08 \uC5C6\uC774.',
      'cta.funding': '\uC5EC\uB7EC\uBD84\uC758 \uD6C4\uC6D0\uC740 \uB354 \uD070 \uBAA8\uB378 \uD14C\uC2A4\uD2B8\uB97C \uC704\uD55C GPU, \uC885\uD569 \uBCA4\uCE58\uB9C8\uD06C\uB97C \uC704\uD55C \uD074\uB77C\uC6B0\uB4DC \uCEF4\uD4E8\uD305, \uADF8\uB9AC\uACE0 \uC624\uD508\uC18C\uC2A4 \uC5F0\uAD6C\uB97C \uC9C0\uC18D\uD558\uB294 \uC2DC\uAC04\uC5D0 \uC9C1\uC811 \uC0AC\uC6A9\uB429\uB2C8\uB2E4.',
      'cta.button': 'Ko-fi\uC5D0\uC11C \uD6C4\uC6D0',
      'footer.name': 'GOBA-AI-Labs',
    },
  };

  const langLabels = { en: 'EN', ja: 'JA', 'zh-CN': 'ZH', 'zh-TW': 'TW', ko: 'KO' };

  function getPreferred() {
    var saved = localStorage.getItem(KEY);
    if (saved && translations[saved]) return saved;
    var nav = (navigator.language || '').toLowerCase();
    if (nav.startsWith('ja')) return 'ja';
    if (nav === 'zh-tw' || nav === 'zh-hant') return 'zh-TW';
    if (nav.startsWith('zh')) return 'zh-CN';
    if (nav.startsWith('ko')) return 'ko';
    return 'en';
  }

  function applyLang(lang) {
    if (!translations[lang]) lang = 'en';
    var t = translations[lang];
    document.querySelectorAll('[data-i18n]').forEach(function (el) {
      var key = el.getAttribute('data-i18n');
      if (t[key] !== undefined) {
        el.innerHTML = t[key];
      }
    });
    document.documentElement.lang = lang === 'zh-CN' ? 'zh-Hans' : lang === 'zh-TW' ? 'zh-Hant' : lang;
    localStorage.setItem(KEY, lang);
    // Update active state in switcher
    document.querySelectorAll('.lang-option').forEach(function (btn) {
      btn.classList.toggle('active', btn.getAttribute('data-lang') === lang);
    });
  }

  document.addEventListener('DOMContentLoaded', function () {
    var lang = getPreferred();
    applyLang(lang);

    // Bind language switcher buttons
    document.querySelectorAll('.lang-option').forEach(function (btn) {
      btn.addEventListener('click', function () {
        applyLang(btn.getAttribute('data-lang'));
      });
    });
  });

  // Export for external use
  window.gobaI18n = { apply: applyLang, get: getPreferred };
})();
